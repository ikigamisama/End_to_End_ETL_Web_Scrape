{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156acc9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shop</th>\n",
       "      <th>name</th>\n",
       "      <th>brand</th>\n",
       "      <th>rating</th>\n",
       "      <th>description</th>\n",
       "      <th>url</th>\n",
       "      <th>variant</th>\n",
       "      <th>price</th>\n",
       "      <th>discounted_price</th>\n",
       "      <th>discount_percentage</th>\n",
       "      <th>...</th>\n",
       "      <th>width</th>\n",
       "      <th>length</th>\n",
       "      <th>gross_weight</th>\n",
       "      <th>net_weight</th>\n",
       "      <th>screen_size</th>\n",
       "      <th>sim_slot</th>\n",
       "      <th>processor</th>\n",
       "      <th>memory</th>\n",
       "      <th>camera</th>\n",
       "      <th>battery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abenson</td>\n",
       "      <td>Samsung Galaxy A56 5G (8GB + 256GB) Awesome Li...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.7-inch FHD+ Super AMOLED Display120Hz Refres...</td>\n",
       "      <td>https://www.abenson.com/samsung-galaxy-a56-5g-...</td>\n",
       "      <td>6.7-inch FHD+, Exynos 1580, 256GB, 5000mAh</td>\n",
       "      <td>25990.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>7.8</td>\n",
       "      <td>16.22</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.25</td>\n",
       "      <td>6.7-inch</td>\n",
       "      <td>Dual SIM + eSIM</td>\n",
       "      <td>Exynos 1580</td>\n",
       "      <td>8GB RAM + 256GB ROM</td>\n",
       "      <td>Rear Camera: 50MP (OIS, Video HDR) + 12MP Ultr...</td>\n",
       "      <td>5000mAh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      shop                                               name    brand rating  \\\n",
       "0  Abenson  Samsung Galaxy A56 5G (8GB + 256GB) Awesome Li...  Samsung    5.0   \n",
       "\n",
       "                                         description  \\\n",
       "0  6.7-inch FHD+ Super AMOLED Display120Hz Refres...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.abenson.com/samsung-galaxy-a56-5g-...   \n",
       "\n",
       "                                      variant    price discounted_price  \\\n",
       "0  6.7-inch FHD+, Exynos 1580, 256GB, 5000mAh  25990.0             None   \n",
       "\n",
       "  discount_percentage  ... width  length  gross_weight  net_weight  \\\n",
       "0                None  ...   7.8   16.22          0.32        0.25   \n",
       "\n",
       "   screen_size         sim_slot    processor               memory  \\\n",
       "0     6.7-inch  Dual SIM + eSIM  Exynos 1580  8GB RAM + 256GB ROM   \n",
       "\n",
       "                                              camera  battery  \n",
       "0  Rear Camera: 50MP (OIS, Video HDR) + 12MP Ultr...  5000mAh  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import asyncio\n",
    "import nest_asyncio\n",
    "import random\n",
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from playwright.async_api import async_playwright\n",
    "from fake_useragent import UserAgent\n",
    "from tenacity import (\n",
    "    retry,\n",
    "    retry_if_exception_type,\n",
    "    stop_after_attempt,\n",
    "    wait_random,\n",
    ")\n",
    "nest_asyncio.apply()\n",
    "\n",
    "headers = {\n",
    "    \"Accept\": 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',\n",
    "    'Accept-Encoding': 'gzip, deflate, br, zstd',\n",
    "    'Accept-Language': 'en-US,en;q=0.9',\n",
    "    'Cache-Control': 'max-age=0',\n",
    "    \"User-Agent\": UserAgent().random,\n",
    "    'Priority': \"u=0, i\",\n",
    "    \"Upgrade-Insecure-Requests\": \"1\",\n",
    "    \"Cookie\": \"wp_ga4_customerGroup=NOT+LOGGED+IN; private_content_version=1fd9b0bb9111f815fb7cc0a2e1b795ad; aws-waf-token=b91f6c13-c3c0-4ec3-a7d8-550794a8bab3:BgoAk3cBOREiAAAA:PKYZTtk3ZLHvTjqbebPH7ufj4dmmpWy1IlXw54gtVwoFfEp98V/nK037tyC5DSvl9OzpfidRLN+1piQTIY2t/NTfkI0XZyGaSMZ/3npm2dZE+AjvhGX6qTmw1wqTX5LRfU22N36ziK2KEU9pZAHu9DJzmdRP1i7Crd1RGecYNV/y3r+7tDwE0A2HqpfwOIMBWFw=\",\n",
    "    \"referer\": 'https://www.abenson.com/mobile/smartphone.html',\n",
    "    \"Sec-Ch-Ua\": \"\\\"Not(A:Brand\\\";v=\\\"99\\\", \\\"Opera GX\\\";v=\\\"118\\\", \\\"Chromium\\\";v=\\\"133\\\"\",\n",
    "    \"Sec-Ch-Ua-Mobile\": \"?0\",\n",
    "    \"Sec-Ch-Ua-Platform\": \"\\\"Windows\\\"\",\n",
    "    \"Sec-Fetch-Dest\": \"document\",\n",
    "    \"Sec-Fetch-Mode\": \"navigate\",\n",
    "    \"Sec-Fetch-Site\": \"same-origin\",\n",
    "    \"Sec-Fetch-User\": \"?1\"\n",
    "}\n",
    "\n",
    "MAX_RETRIES = 10\n",
    "MAX_WAIT_BETWEEN_REQ = 2\n",
    "MIN_WAIT_BETWEEN_REQ = 0\n",
    "REQUEST_TIMEOUT = 30\n",
    "\n",
    "class ProductsETL():\n",
    "    def __init__(self):\n",
    "        self.session = requests.Session()\n",
    "        \n",
    "    @retry(\n",
    "        wait=wait_random(min=MIN_WAIT_BETWEEN_REQ, max=MAX_WAIT_BETWEEN_REQ),\n",
    "        stop=stop_after_attempt(MAX_RETRIES),\n",
    "        retry=retry_if_exception_type(requests.RequestException),\n",
    "        reraise=True,\n",
    "    )\n",
    "    async def extract_scrape_content(self, url, selector):\n",
    "        soup = None\n",
    "        browser = None\n",
    "        try:\n",
    "            async with async_playwright() as p:\n",
    "                browser_args = {\n",
    "                    \"headless\": True,\n",
    "                    \"args\": [\"--disable-blink-features=AutomationControlled\"]\n",
    "                }\n",
    "\n",
    "                browser = await p.chromium.launch(**browser_args)\n",
    "                context = await browser.new_context(\n",
    "                    locale=\"en-US\",\n",
    "                    user_agent=UserAgent().random,\n",
    "                    viewport={\"width\": 1280, \"height\": 800},\n",
    "                    device_scale_factor=1,\n",
    "                    is_mobile=False,\n",
    "                    has_touch=False,\n",
    "                    screen={\"width\": 1280, \"height\": 800},\n",
    "                    permissions=[\"geolocation\"],\n",
    "                    geolocation={\"latitude\": 14.5995, \"longitude\": 120.9842},\n",
    "                    timezone_id=\"Asia/Manila\"\n",
    "                )\n",
    "\n",
    "                page = await context.new_page()\n",
    "\n",
    "                await page.add_init_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
    "                await page.set_extra_http_headers(headers)\n",
    "                await page.goto(url, wait_until=\"domcontentloaded\")\n",
    "                await page.wait_for_selector(selector, timeout=30000)\n",
    "\n",
    "                for _ in range(random.randint(3, 6)):\n",
    "                    await page.mouse.wheel(0, random.randint(300, 700))\n",
    "                    await asyncio.sleep(random.uniform(0.5, 1))\n",
    "\n",
    "                for _ in range(random.randint(5, 10)):\n",
    "                    await page.mouse.move(random.randint(0, 800), random.randint(0, 600))\n",
    "                    await asyncio.sleep(random.uniform(0.5, 1))\n",
    "\n",
    "                rendered_html = await page.content()\n",
    "                return BeautifulSoup(rendered_html, \"html.parser\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "\n",
    "        finally:\n",
    "            if browser:\n",
    "                await browser.close()\n",
    "\n",
    "    async def _scroll_products(self, url):\n",
    "        soup = None\n",
    "        browser = None\n",
    "        try:\n",
    "            async with async_playwright() as p:\n",
    "                browser_args = {\n",
    "                    \"headless\": True,\n",
    "                    \"args\": [\"--disable-blink-features=AutomationControlled\"]\n",
    "                }\n",
    "\n",
    "                browser = await p.chromium.launch(**browser_args)\n",
    "                context = await browser.new_context(\n",
    "                    user_agent=UserAgent().random,\n",
    "                    viewport={\"width\": random.randint(\n",
    "                        1200, 1600), \"height\": random.randint(800, 1200)},\n",
    "                    locale=\"en-US\"\n",
    "                )\n",
    "\n",
    "                page = await context.new_page()\n",
    "                await page.set_extra_http_headers(headers)\n",
    "\n",
    "                await page.goto(url, wait_until=\"domcontentloaded\")\n",
    "                await page.wait_for_selector('#root-product-list', timeout=30000)\n",
    "\n",
    "                print(\n",
    "                    \"Starting to scrape the product list (Infinite scroll scrape)...\")\n",
    "\n",
    "                scroll_step = 1500\n",
    "                scroll_delay = 5\n",
    "\n",
    "                previous_count = 0\n",
    "                same_count_retries = 0\n",
    "                max_retries = 3\n",
    "\n",
    "                while True:\n",
    "                    # Scroll to the bottom\n",
    "                    await page.evaluate(f'window.scrollBy(0, {scroll_step})')\n",
    "                    await asyncio.sleep(scroll_delay)\n",
    "\n",
    "                    # Check if the spinner exists\n",
    "                    current_count = await page.evaluate(\"\"\"\n",
    "                        () => document.querySelectorAll('div.item-siminia-product-grid-item-3do').length\n",
    "                    \"\"\")\n",
    "\n",
    "                    print(f\"Current item count: {current_count}\")\n",
    "\n",
    "                    if current_count > previous_count:\n",
    "                        previous_count = current_count\n",
    "                        scroll_step += scroll_step\n",
    "                        same_count_retries = 0\n",
    "                    else:\n",
    "                        same_count_retries += 1\n",
    "                        print(f\"No new items loaded. Retry {same_count_retries}/{max_retries}\")\n",
    "\n",
    "                        if same_count_retries >= max_retries:\n",
    "                            print(\"No more items being loaded. Done scrolling.\")\n",
    "                            break\n",
    "\n",
    "                print(\"Scraping complete. Extracting content...\")\n",
    "\n",
    "                rendered_html = await page.content()\n",
    "                print(\n",
    "                    f\"Successfully extracted data from {url}\"\n",
    "                )\n",
    "                soup = BeautifulSoup(rendered_html, \"html.parser\")\n",
    "                return soup.find_all('div', class_=\"item-siminia-product-grid-item-3do\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "\n",
    "        finally:\n",
    "            if browser:\n",
    "                await browser.close()\n",
    "\n",
    "    def extract_from_url(self, method: str, url: str, params: dict = None, data: dict = None, headers: dict = None, verify: bool = True) -> BeautifulSoup:\n",
    "        try:\n",
    "            # Parse request response\n",
    "            response = self.session.request(\n",
    "                method=method, url=url, params=params, data=data, headers=headers, verify=verify)\n",
    "            response.raise_for_status()\n",
    "            soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "            print(\n",
    "                f\"Successfully extracted data from {url} {response.status_code}\"\n",
    "            )\n",
    "            sleep_time = random.uniform(\n",
    "                MIN_WAIT_BETWEEN_REQ, MAX_WAIT_BETWEEN_REQ)\n",
    "            print(f\"Sleeping for {sleep_time} seconds...\")\n",
    "            return soup\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error in parsing {url}: {e}\")\n",
    "    \n",
    "    def transform(self, soup, url):\n",
    "        product_shop = 'Abenson'\n",
    "        product_name = soup.find('h1', class_=\"productFullDetail-productName-2jb\").get_text()\n",
    "        product_brand = soup.find('meta', attrs={'itemprop': 'brand'}).get('content')\n",
    "        product_rating = soup.find('span', class_=\"productReview-averageReview-qT6\").get_text()\n",
    "        product_description = soup.find('meta', attrs={'itemprop': 'description'}).get('content')\n",
    "        product_url = url\n",
    "        product_variant = soup.find('section', class_=\"productFullDetail-shortDesc-1L9\").get_text()\n",
    "        product_image_url = soup.find('meta', attrs={'itemprop': 'image'}).get('content')\n",
    "\n",
    "        discount_price_soup = soup.find('span', class_=\"productFullDetail-specialPrice-1wb\")\n",
    "        if discount_price_soup:\n",
    "            price_html = [s.get_text() for s in soup.find('span', class_=\"productFullDetail-specialPrice-1wb\").find_all('span')]\n",
    "            price_str =  ''.join(price_html[1:])\n",
    "            price = float(price_str.replace(',',''))\n",
    "\n",
    "            discounted_price_html = [s.get_text() for s in soup.find('span', class_=\"productFullDetail-regularPrice-188\").find_all('span')]\n",
    "            discounted_price_str =  ''.join(discounted_price_html[1:])\n",
    "            discounted_price = float(discounted_price_str.replace(',',''))\n",
    "\n",
    "            discount_percentage = float(soup.find('span', class_=\"productFullDetail-saleOff-a4h\").get_text().replace('-', '').replace('%', '')) / 100\n",
    "        else:\n",
    "            price_html = [s.get_text() for s in soup.find('span', class_=\"productFullDetail-regularPrice-188\").find_all('span')]\n",
    "            price_str =  ''.join(price_html[1:])\n",
    "            price = float(price_str.replace(',',''))\n",
    "\n",
    "            discounted_price = None\n",
    "            discount_percentage = None\n",
    "\n",
    "        feature_data = {\n",
    "            'height': None,\n",
    "            'width': None,\n",
    "            'length': None,\n",
    "            'gross_weight': None,\n",
    "            'net_weight': None,\n",
    "            'screen_size': None,\n",
    "            'sim_slot': None,\n",
    "            'processor': None,\n",
    "            'memory': None,\n",
    "            'camera': None,\n",
    "            'battery': None\n",
    "        }\n",
    "        feature_blocks = soup.find_all('div', class_='features-block-2mF')\n",
    "        for block in feature_blocks:\n",
    "            title = block.find('div', class_='features-blockTitle-hWK')\n",
    "            if title and title.get_text(strip=True).lower() == 'highlights':\n",
    "                highlights = block.find_all('div', class_='features-highlight-1V0')\n",
    "                for item in highlights:\n",
    "                    spans = item.find_all('span')\n",
    "                    if len(spans) >= 3:\n",
    "                        label = spans[0].get_text(strip=True).lower()\n",
    "                        value = spans[2].get_text(strip=True)\n",
    "\n",
    "                        if 'height' in label:\n",
    "                            feature_data['height'] = float(value)\n",
    "                        elif 'width' in label:\n",
    "                            feature_data['width'] = float(value)\n",
    "                        elif 'length' in label:\n",
    "                            feature_data['length'] = float(value)\n",
    "                        elif 'gross weight' in label:\n",
    "                            feature_data['gross_weight'] = float(value)\n",
    "                        elif 'net weight' in label:\n",
    "                            feature_data['net_weight'] = float(value)\n",
    "                        elif 'screen size' in label:\n",
    "                            feature_data['screen_size'] = value\n",
    "                        elif 'sim slot' in label:\n",
    "                            feature_data['sim_slot'] = value\n",
    "                        elif 'processor' in label:\n",
    "                            feature_data['processor'] = value\n",
    "                        elif 'memory' in label:\n",
    "                            feature_data['memory'] = value\n",
    "                        elif 'camera' in label:\n",
    "                            feature_data['camera'] = value\n",
    "                        elif 'battery' in label:\n",
    "                            feature_data['battery'] = value\n",
    "\n",
    "        data = {\n",
    "            'shop': product_shop,\n",
    "            'name': product_name,\n",
    "            'brand': product_brand,\n",
    "            'rating': product_rating,\n",
    "            'description': product_description,\n",
    "            'url': product_url,\n",
    "            'variant': product_variant,\n",
    "            'price': price,\n",
    "            'discounted_price': discounted_price,\n",
    "            'discount_percentage': discount_percentage,\n",
    "            'image_url': product_image_url,\n",
    "            'height': feature_data['height'],\n",
    "            'width': feature_data['width'],\n",
    "            'length': feature_data['length'],\n",
    "            'gross_weight': feature_data['gross_weight'],\n",
    "            'net_weight': feature_data['net_weight'],\n",
    "            'screen_size': feature_data['screen_size'],\n",
    "            'sim_slot': feature_data['sim_slot'],\n",
    "            'processor': feature_data['processor'],\n",
    "            'memory': feature_data['memory'],\n",
    "            'camera': feature_data['camera'],\n",
    "            'battery': feature_data['battery']\n",
    "        }\n",
    "\n",
    "        return pd.DataFrame([data])\n",
    "    \n",
    "    def extract_links(self, url: str) -> pd.DataFrame:\n",
    "        soup_product_list = asyncio.run(self._scroll_products(url))\n",
    "        urls = ['https://www.abenson.com' + product_html.find('a').get('href') for product_html in soup_product_list]\n",
    "    \n",
    "        df = pd.DataFrame({\"url\": urls})\n",
    "        df.insert(0, \"shop\", \"Abenson\")\n",
    "        return df\n",
    "\n",
    "e = ProductsETL()\n",
    "e.extract_links('https://www.abenson.com/mobile/smartphone.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
